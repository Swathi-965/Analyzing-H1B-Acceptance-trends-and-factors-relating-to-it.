{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RFnPSdxLC6em"
   },
   "source": [
    "## Analysing H1B Acceptance Trends "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uh8CJdwBJOAL"
   },
   "source": [
    "H1B visa is a nonimmigrant visa issued to gradute level applicants allowing them to work in the United States. The employer sponsors the H1B visa for workers with theoretical or technical expertise in specialized fields such as in IT, finance, accounting etc. An interesting fact about immigrant workers is that about 52 percent of new Silicon valley companies were founded by such workers during 1995 and 2005. Some famous CEOs like Indira Nooyi (Pepsico), Elon Musk (Tesla), Sundar Pichai (Google),Satya Nadella (Microsoft) once arrived to the US on a H1B visa.\\\n",
    "**Motivation**: Our team consists of five international gradute students, in the future we will be applying for H1B visa. The visa application process seems very long, complicated and uncertain. So we decided to understand this process and use Machine learning algorithms to predict the acceptance rate and trends of H1B visa. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kjQ8YI2GTfb6"
   },
   "source": [
    "### Data \n",
    "The data used in the project has been collected from <a href=\"https://www.foreignlaborcert.doleta.gov/performancedata.cfm\">the Office of Foreign Labor Certification (OFLC).</a>The Data provides insight into each petition with information such as the Job title, Wage, Employer, Worksite location etc. To get the dataset click on the above link-> click on Disclosure data -> scroll down to H1B data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "ZNTPm7WVCsm4",
    "outputId": "afc52910-8e7b-4f66-e790-18756ccb63d4"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "colab_type": "code",
    "id": "_sSzHVSl3-bD",
    "outputId": "a0b9c1e5-bf0c-4fac-bb2a-0d72df2914ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Charic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Charic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install autocorrect\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk,warnings\n",
    "import clean_wage as cw\n",
    "import drop as dp\n",
    "import baseline as blc\n",
    "%matplotlib inline\n",
    "import remove\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from statistics import mean\n",
    "nltk.download('words')\n",
    "from autocorrect import Speller \n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import OneHotEncoder #ONE HOT ENCODING\n",
    "from sklearn.ensemble import RandomForestClassifier #Build model - Random Forest Classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FARuLUkuV7T8"
   },
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pleklaelV_xO"
   },
   "source": [
    "Before we begin working on our data we need to understand the traits of our data which we accomplish using EDA. We see that we have about 260 columns , not all 260 columns have essential information that contributes to our analysis. Hence we pick out the columns such as case status( Accepted/ Denied) ,Employer, Job title etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "iCiYlOyXHHKJ",
    "outputId": "524360e6-d6c2-43b9-ca76-558d3271991e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charic\\Documents\\Python_Scripts\\2_semester\\data_science_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3051: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,13,14,19,20,21,22,23,24,25,26,27,28,29,31,32,33,34,35,36,37,38,39,40,41,42,43,45,46,47,48,49,50,51,52,53,54,55,57,58,59,61,64,66,67,68,69,70,71,72,73,76,78,79,80,82,85,87,88,89,90,91,92,93,94,97,98,99,100,101,103,106,108,109,110,111,112,113,114,115,121,122,124,127,129,130,131,132,133,134,135,136,142,143,145,148,150,151,152,153,154,155,156,157,160,162,163,164,166,169,171,172,173,174,175,176,177,178,184,185,187,190,192,193,194,195,196,197,198,199,205,206,208,211,213,214,215,216,217,218,219,220,223,225,226,227,229,232,234,235,236,237,238,239,240,244,246,247,248,250,253,254,255,256,257,258,259) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# file=pd.read_csv('/content/gdrive/My Drive/H-1B_Disclosure_Data_FY2019.csv')#Read the csv file and store it in file\n",
    "#file = pd.read_csv(\"C:\\\\Users\\\\bodav\\\\OneDrive\\\\H-1B_Disclosure_Data_FY2019.csv\")\n",
    "file=pd.read_csv('../data/H-1B_Disclosure_Data_FY2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "ZxxeAh5SX0Bc",
    "outputId": "15970129-7c77-4bb3-eafa-1d6b448d1655"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048548, 15)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned=file[['CASE_NUMBER','CASE_STATUS','CASE_SUBMITTED','DECISION_DATE','VISA_CLASS','FULL_TIME_POSITION','JOB_TITLE','SOC_CODE','SOC_TITLE',\\\n",
    "              'EMPLOYER_NAME','WAGE_RATE_OF_PAY_FROM_1','WAGE_UNIT_OF_PAY_1','NAICS_CODE','WORKSITE_CITY_1','WORKSITE_STATE_1']]\n",
    "cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "colab_type": "code",
    "id": "BbgGJEB9XpO6",
    "outputId": "e23464b5-8936-4f80-c33e-e2bf97685151"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H-1B               649083\n",
      "E-3 Australian      13087\n",
      "H-1B1 Singapore      1291\n",
      "H-1B1 Chile          1155\n",
      "Name: VISA_CLASS, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charic\\Documents\\Python_Scripts\\2_semester\\data_science_env\\lib\\site-packages\\pandas\\core\\frame.py:3994: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "C:\\Users\\Charic\\Documents\\Python_Scripts\\2_semester\\data_science_env\\lib\\site-packages\\pandas\\core\\frame.py:4169: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  method=method,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 629856 entries, 18 to 664616\n",
      "Data columns (total 15 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   CASE_NUMBER              629855 non-null  object \n",
      " 1   CASE_STATUS              629856 non-null  object \n",
      " 2   CASE_SUBMITTED           629856 non-null  object \n",
      " 3   DECISION_DATE            629856 non-null  object \n",
      " 4   VISA_CLASS               629856 non-null  object \n",
      " 5   FULL_TIME_POSITION       629856 non-null  int64  \n",
      " 6   JOB_TITLE                629856 non-null  object \n",
      " 7   SOC_CODE                 629852 non-null  object \n",
      " 8   SOC_TITLE                629852 non-null  object \n",
      " 9   EMPLOYER_NAME            629848 non-null  object \n",
      " 10  WAGE_RATE_OF_PAY_FROM_1  629852 non-null  object \n",
      " 11  WAGE_UNIT_OF_PAY_1       629852 non-null  object \n",
      " 12  NAICS_CODE               629855 non-null  float64\n",
      " 13  WORKSITE_CITY_1          629785 non-null  object \n",
      " 14  WORKSITE_STATE_1         629845 non-null  object \n",
      "dtypes: float64(1), int64(1), object(13)\n",
      "memory usage: 76.9+ MB\n"
     ]
    }
   ],
   "source": [
    "print(cleaned['VISA_CLASS'].value_counts()) # similarly we can find the categories in CASE_STATUS and 'FULL_TIME_POSITION'\n",
    "# Visa class has many categories which are not of use , we require only H1B visa type , hence we drop all records with other visa types\n",
    "cleaned.drop(labels=cleaned.loc[cleaned['VISA_CLASS']!='H-1B'].index , inplace=True)\n",
    "#In case status we can drop withdrawn records and we can change certified-withdrawn to certified\n",
    "cleaned.replace({\"CASE_STATUS\":\"CERTIFIED-WITHDRAWN\"},\"CERTIFIED\",inplace=True)\n",
    "cleaned.drop(labels=cleaned.loc[cleaned['CASE_STATUS']=='WITHDRAWN'].index , inplace=True)\n",
    "cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "F5SSKy8mVr01",
    "outputId": "49b2b74f-7d42-4d72-d011-e78748e6d950"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bodav\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Year         587386\n",
       "Hour          41927\n",
       "Month           342\n",
       "Bi-Weekly       105\n",
       "Week             92\n",
       "Name: WAGE_UNIT_OF_PAY_1, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the column wages has a mix of both string and float value types and some record have the symbol '$' which we want to remove\n",
    "cleaned['WAGE_RATE_OF_PAY_FROM_1'].apply(type).value_counts()\n",
    "cleaned['WAGES']=cleaned['WAGE_RATE_OF_PAY_FROM_1'].apply(cw.clean_wages).astype('float')\n",
    "cleaned['WAGE_UNIT_OF_PAY_1'].value_counts()# the wage information that we have available has different unit of pay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "colab_type": "code",
    "id": "hCGTUT22Z6Bj",
    "outputId": "9360fdd5-bf82-44c4-f6a9-f4036eaaabb4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bodav\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\bodav\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bodav\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\bodav\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\bodav\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# we convert the different units of pay to the type 'Year'\n",
    "cleaned= dp.clean_wageUnit(np,cleaned)\n",
    "cleaned.drop(columns=['WAGE_RATE_OF_PAY_FROM_1','WAGE_UNIT_OF_PAY_1'],axis=1,inplace=True)#we can drop the columns as cleaning is complete\n",
    "cleaned.dropna(inplace=True)# We can check if we have null records using cleaned.info() and drop null records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M03_5gLDxgYT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bodav\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\bodav\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\bodav\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bodav\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "cleaned['JOB_TITLE']=cleaned.JOB_TITLE.apply(lambda txt: \" \".join([cw.remove_num(i) for i in txt.lower().split()]))\n",
    "cleaned['JOB_TITLE']=cleaned['JOB_TITLE'].str.replace(',', '')\n",
    "cleaned['SOC_TITLE']=cleaned.SOC_TITLE.apply(lambda txt: \" \".join([cw.remove_num(i) for i in txt.lower().split()]))\n",
    "cleaned['SOC_TITLE']=cleaned['SOC_TITLE'].str.replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3DxeRz6Mxkx1"
   },
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "words = set(nltk.corpus.words.words())\n",
    "spell = Speller()\n",
    "def lemmatize_text(text):\n",
    "     return lemmatizer.lemmatize(text)\n",
    "def spelling_checker(text):\n",
    "     return spell(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zMiGTMl414Mq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bodav\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\bodav\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\bodav\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\bodav\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "cleaned['JOB_TITLE']=cleaned.JOB_TITLE.apply(lambda txt: \" \".join([lemmatize_text(i) for i in txt.lower().split()]))\n",
    "cleaned['JOB_TITLE']=cleaned.JOB_TITLE.apply(lambda txt: \" \".join([spelling_checker(i) for i in txt.lower().split()]))\n",
    "cleaned['SOC_TITLE']=cleaned.SOC_TITLE.apply(lambda txt: \" \".join([lemmatize_text(i) for i in txt.lower().split()]))\n",
    "cleaned['SOC_TITLE']=cleaned.SOC_TITLE.apply(lambda txt: \" \".join([spelling_checker(i) for i in txt.lower().split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "14afdxukP4iT",
    "outputId": "58e05c9c-2648-4351-bb21-586b3b3ea1ac"
   },
   "outputs": [],
   "source": [
    "cleaned= dp.drop_less_significant(cleaned)\n",
    "cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "iBMWRKQo14Mv",
    "outputId": "6485bb54-44be-4e6b-9a4e-942c65e438c2"
   },
   "outputs": [],
   "source": [
    "\n",
    "cleaned['WAGE_CATEGORY'] = cleaned['WAGES'].apply(remove.wage_feature_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IARZcE10wHBl"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleaned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-cdb1864afbc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcleaned\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'EMPLOYER_NAME'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mTop_Employer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcleaned\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'EMPLOYER_NAME'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTop_Employer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTop_Employer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpalette\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolor_palette\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'viridis'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtick_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabelsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cleaned' is not defined"
     ]
    }
   ],
   "source": [
    "cleaned['EMPLOYER_NAME'].value_counts()\n",
    "Top_Employer=cleaned['EMPLOYER_NAME'].value_counts()[:10]\n",
    "plt.figure(figsize=[8,8])\n",
    "ax=sns.barplot(y=Top_Employer.index,x=Top_Employer.values,palette=sns.color_palette('viridis',10))\n",
    "ax.tick_params(labelsize=12)\n",
    "for i, v in enumerate(Top_Employer.values): \n",
    "    ax.text(.5, i, v,fontsize=15,color='white',weight='bold')\n",
    "plt.title('Top 10 Companies sponsoring H1B Visa in 2019', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pdms5n6Fz7SO"
   },
   "outputs": [],
   "source": [
    "state={\"AL\":\"ALABAMA\",\"AK\":\"ALASKA\",\"AZ\":\"ARIZONA\",\"AR\":\"ARKANSAS\",\"CA\":\"CALIFORNIA\",\"CO\":\"COLORADO\",\"DE\":\"DELAWARE\",\\\n",
    "       \"FL\":\"FLORIDA\",\"GA\":\"GEORGIA\",\"HI\":\"HAWAII\",\"ID\":\"IDAHO\",\"IL\":\"ILLINOIS\",\"IN\":\"INDIANA\",\"IA\":\"IOWA\",\"KS\":\"KANSAS\",\\\n",
    "       \"KY\":\"KENTUCKY\",\"LA\":\"LOUISIANA\",\"ME\":\"MAINE\",\"MD\":\"MARYLAND\",\"MA\":\"MASSACHUSETTS\",\"MI\":\"MICHIGAN\",\"MN\":\"MINNESOTA\",\\\n",
    "       \"MS\":\"MISSISSIPPI\",\"MO\":\"MISSOURI\",\"MT\":\"MONTANA\",\"NE\":\"NEBRASKA\",\"NV\":\"NEVADA\",\"NH\":\"NEW HAMPSHIRE\",\"NJ\":\"NEW JERSEY\",\\\n",
    "       \"NM\":\"NEW MEXICO\",\"NY\":\"NEW YORK\",\"NC\":\"NORTH CAROLINA\",\"ND\":\"NORTH DAKOTA\",\"OH\":\"OHIO\",\"OK\":\"OKLAHOMA\",\"OR\":\"OREGON\",\\\n",
    "       \"PA\":\"PENNSYLVANIA\",\"RI\":\"RHODE ISLAND\",\"SC\":\"SOUTH CAROLINA\",\"SD\":\"SOUTH DAKOTA\",\"TN\":\"TENNESSEE\",\"TX\":\"TEXAS\",\\\n",
    "       \"UT\":\"UTAH\",\"VT\":\"VERMONT\",\"VA\":\"VIRGINIA\",\"WA\":\"WASHINGTON\",\"WV\":\"WEST VIRGINIA\",\"WI\":\"WISCONSIN\",\"WY\":\"WYOMING\",\\\n",
    "       \"PR\":\"PUERTO RICO\",\"VI\":\"U.S. VIRGIN ISLANDS\",\"MP\":\"NORTHERN MARIANA ISLANDS\",\"GU\":\"GUAM\",\"MH\":\"MARSHALL ISLANDS\",\\\n",
    "       \"PW\":\"PALAU\",\"DC\":\"DISTRICT OF COLUMBIA\",\"CT\":\"CONNECTICUT\"}\n",
    "cleaned.replace({\"WORKSITE_STATE_1\": state})\n",
    "cleaned = cleaned.groupby(\"WORKSITE_STATE_1\").filter(lambda x: len(x) > 15) #removing less significant records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wIUdVPMR14Nj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charic\\Documents\\Python_Scripts\\2_semester\\data_science_env\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:252: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    }
   ],
   "source": [
    "#CONVERTING CATEGORICAL COLUMNS INTO NUMERIC COLUMNS\n",
    "cleaned.loc[(cleaned.CASE_STATUS == \"CERTIFIED\"),\"CASE_STATUS\"] = 1\n",
    "cleaned.loc[(cleaned.CASE_STATUS == \"DENIED\"),\"CASE_STATUS\"] = 0\n",
    "cleaned.loc[(cleaned.FULL_TIME_POSITION == \"Y\"),\"FULL_TIME_POSITION\"] = 1\n",
    "cleaned.loc[(cleaned.FULL_TIME_POSITION == \"N\"),\"FULL_TIME_POSITION\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lw2l9vMB14Nt"
   },
   "source": [
    "### Baseline classifier\n",
    "\n",
    "The baseline classifier is done with a basic model. In this case we are taking the mean of the labels ('certified' and 'denied' for H1B visa approvals). It will give us the base accuracy to which we will compare our classifier's accuracy. Our classifier should have a better accuracy than the baseline classifier accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kBUpRntv14Nu",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This step assigns a binary class label (0 or 1) to each label for H1B visa approval. \n",
    "def create_class_labels(processed_data):\n",
    "    y = np.where((processed_data['CASE_STATUS']== 1),1, 0)\n",
    "    return y\n",
    "X = cleaned['CASE_STATUS'].to_numpy()\n",
    "y = create_class_labels(cleaned)# Groundtruth labels for the dataset\n",
    "counts = cleaned['CASE_STATUS'].value_counts()\n",
    "print(counts)\n",
    "print('proportion: ', counts[0]/counts[1], ': 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iwmIZYCt14Nz"
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(validation, predicted):\n",
    "    comp = prediction == validation \n",
    "    match_counts = np.count_nonzero(comp == True) \n",
    "    clasifier_accuracy = match_counts/len(validation)\n",
    "    return clasifier_accuracy  \n",
    "def compute_AUC(y, prediction):\n",
    "    auc = None\n",
    "    try:\n",
    "        auc = roc_auc_score(y, prediction)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1gr9AgXB14N4"
   },
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "AUCs = []\n",
    "kf = sklearn.model_selection.KFold(n_splits=4, random_state=1, shuffle=True)# Testing with K-folds \n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    X_train, X_test, y_train, y_test = X[train_idx], X[test_idx], y[train_idx], y[test_idx] \n",
    "    prediction = blc.run_clasifier(X_train, y_train, X_test, np)\n",
    "    fold_accuracy = compute_accuracy(y_test, prediction)\n",
    "    fold_AUC = compute_AUC(y_test, prediction)\n",
    "    accuracies.append(fold_accuracy)\n",
    "    if fold_AUC != None: AUCs.append(fold_AUC)\n",
    "baseline_clasifier_accuracy = mean(accuracies)\n",
    "print('Baseline accuracy: ', baseline_clasifier_accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2WJnr6p414N7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)# Testing with regular split\n",
    "prediction = blc.run_clasifier(X_train, y_train, X_test, np)\n",
    "split_accuracy = compute_accuracy(y_test, prediction)\n",
    "split_AUC = compute_AUC(y_test, prediction)\n",
    "print('Baseline accuracy: ', split_accuracy)  \n",
    "print('AUC K-fold: ', mean(AUCs))\n",
    "print('AUC split (80-20): ', split_AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oyr0Q6LN14OA"
   },
   "source": [
    "The accuracy results of the baseline classifier is 0.99. In this case, a performance measure based on the accuracy is not a good one. A better performance measure in imbalanced data is the Area under the ROC Curve (AUC). It meassures the likelihood that given two random points (one from the positive and one from the negative class) the classifier will rank the point from the positive class higher than the one from the negative one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "me1Gx1mr14OO"
   },
   "outputs": [],
   "source": [
    "Dataset = cleaned[[\"CASE_STATUS\", \"FULL_TIME_POSITION\",\"JOB_TITLE\", \"SOC_CODE\", \"SOC_TITLE\", \"EMPLOYER_NAME\", \"WORKSITE_STATE_1\", \"WAGE_CATEGORY\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bodav\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "def soc_code(x):\n",
    "    if x in y:\n",
    "        return x\n",
    "    else:\n",
    "        return 0\n",
    "y = Dataset[\"SOC_CODE\"].value_counts().head(70)\n",
    "Dataset[\"TOP_SOC_CODE\"] = Dataset[\"SOC_CODE\"].apply(common_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bodav\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "C:\\Users\\bodav\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\bodav\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "def common_function(x):\n",
    "    if x in y:\n",
    "        return x\n",
    "    else:\n",
    "        return \"others\"\n",
    "y = Dataset[\"JOB_TITLE\"].value_counts().head(72)\n",
    "Dataset[\"JOB_POSITION\"] = Dataset[\"JOB_TITLE\"].apply(common_function)\n",
    "y = Dataset[\"SOC_TITLE\"].value_counts().head(70)\n",
    "Dataset[\"TOP_SOC_TITLE\"] = Dataset[\"SOC_TITLE\"].apply(common_function)\n",
    "y = Dataset[\"EMPLOYER_NAME\"].value_counts().head(70)\n",
    "Dataset[\"TOP_EMPLOYER\"] = Dataset[\"EMPLOYER_NAME\"].apply(common_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JdKSXCt714Ol"
   },
   "outputs": [],
   "source": [
    "Dataset.drop(columns=['JOB_TITLE','SOC_CODE','SOC_TITLE','EMPLOYER_NAME',],axis=1,inplace=True)\n",
    "Encoding = OneHotEncoder(handle_unknown='ignore',sparse = True)\n",
    "Encoding_df = pd.DataFrame(Encoding.fit_transform(Dataset[[\"WORKSITE_STATE_1\",\"JOB_POSITION\",\"TOP_SOC_CODE\",\"TOP_SOC_TITLE\",\"TOP_EMPLOYER\"]]).toarray())\n",
    "Dataset = Dataset.join(Encoding_df)\n",
    "Dataset.drop(columns=['WORKSITE_STATE_1','JOB_POSITION','TOP_SOC_CODE','TOP_SOC_TITLE','TOP_EMPLOYER','WAGE_CATEGORY'],axis=1,inplace=True)\n",
    "Y = Dataset['CASE_STATUS'].values\n",
    "X = Encoding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wtqqupdU14O1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bodav\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.9950902755780805\n"
     ]
    }
   ],
   "source": [
    "Y = Dataset['CASE_STATUS'].values\n",
    "X = Encoding_df\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=20)#Split the date into training and test set\n",
    "model_clf = RandomForestClassifier(n_jobs=2,random_state=0)\n",
    "model_clf.fit(X_train,y_train)#train the model\n",
    "prediction_test = model_clf.predict(X_test)#test the model (predict with our test data)\n",
    "print(\"Accuracy = \", metrics.accuracy_score(y_test, prediction_test))#compare with original value, Y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HMPmHHbo14PE"
   },
   "source": [
    "### Reflection\n",
    "What is the hardest part of the project that you’ve encountered so far?\n",
    "    Setting up the data for visualization and ML analysis, e.g. same job title is cluttered with different words, integers, and punctuation characters. Encoding the dataset to be used in the Classifier was one the hardest part, which was later resolved by considering only the most values .\n",
    "   \n",
    "Are there any concrete results you can show at this point? If not, why not?\n",
    "    The concrete result that we have achieved is the acceptance of the H1B visa can be predicted, based on the Random-Forest-Classifier, which has shown 99% accuracy.\n",
    "    \n",
    "Going forward, what are the current biggest problems you’re facing?\n",
    "    One the issues we might encounter in the upcoming stages is that normalizing the data with 'SMOTE' and handling additional data that will be included.\n",
    "    \n",
    "Do you think you are on track with your project? If not, what parts do you need to dedicate more time to?\n",
    "    We are track with the project and will be able to accomplish all the results within the stipulated timeframe.\n",
    "    \n",
    "Given your initial exploration of the data, is it worth proceeding with your project, why? If not, how are you going to change your project and why do you think it’s better than your current results?\n",
    "    On the lines of the initial exploration, we conclude that proceeding with are project is worthy.\n",
    "    \n",
    "    \n",
    "### Next steps: \n",
    "What you plan to accomplish in the next month and how you plan to evaluate whether your project achieved the goals you set for it?\n",
    "    In the next month we plan to accomplish and present valid outcomes , we plan to apply another Machine-Learning Algorithm, predict the acceptance rates and provide another visualization based on the different states and their acceptance rates and also showcase the difference in the H1B visa acceptance after the policies that were enforced in the recent years. We will also combine the data from additional years.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Progress_Report.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
